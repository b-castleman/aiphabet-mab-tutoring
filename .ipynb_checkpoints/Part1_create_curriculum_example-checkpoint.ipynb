{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Complete!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "from graphviz import Digraph\n",
    "import sys\n",
    "from tree import Build_Tree, Static_Tree, Build_Tree_Data\n",
    "from compare_functions import compare_ngrams\n",
    "import re\n",
    "import os\n",
    "import copy\n",
    "print('Importing Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The ZPDES_Memory algorithm requires a curriculum graph in the form of a tree structure. This notebooks gives two examples of creating this tree.\n",
    "1. Build_Tree will build the tree structure based on a trace based analysis of an execution trace or sentence trace as given in [1, 2]\n",
    "2. Static_Tree takes in a predefined graph in the form of a dictionary that maps nodes to its immediate children to create a tree structure.\n",
    "\n",
    "[1] Andersen, Erik, Sumit Gulwani, and Zoran Popovic. \"A trace-based framework for analyzing and synthesizing educational progressions.\" Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, 2013.<br>\n",
    "[2] Wang, Shuhan, Fang He, and Erik Andersen. \"A unified framework for knowledge assessment and progression analysis and design.\" Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example Progression\n",
    "\n",
    "We refer to each node of the graph to be a *concept*. We refer to a practice item that a student can complete as a *problem*. Each concept can have one or more problems. Each problem should only belong to one concept. We work for hashable representations for concepts and problems (in our example data, these representations are strings).\n",
    "\n",
    "For both methods, a couple of parameters need to be defined:\n",
    "1. all_concepts: a list of all concepts in the curriculum graph, these are the nodes in the curriculum graph\n",
    "2. concept_problems: a dictionary mapping concept to problems. In the example data below, the problems 'cat', 'tas', and 'cas' coorespond to the concept of 'SAS'. Note there can also be the case where every concept corresponds to one unique problem.\n",
    "3. problem_components: a dictionary mapping problem to basic components(if defined). In the example data below the basic components 'r' and 'c' make up the problem 'rc'. Note that there can also be the case where basic components are not defined, in this case every problem corresponds to one unique basic component (see the ```if problem_components is None or all_basic_components is None``` case).\n",
    "3. all_basic_components: a list of all basic components that make up the problems (if defined). If not defined, then this should be a list of all problems (see the ```if problem_components is None or all_basic_components is None``` case).\n",
    "\n",
    "In this example, we will create the following target curriculum graph:\n",
    "![tree_example_graph.png](attachment:tree_example_graph.png)\n",
    "\n",
    "Where *'Root'* is a dummy root node the connects to all nodes that don't have any prerequisites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nall_concepts = ['S' ,'N', 'C', 'CS', 'SAS', 'CAC', 'CSACS', 'NCS', 'NCSANCS']\\nconcept_problems = {\\n    'S': ['t', 'c', 's'],\\n    'C': ['r', 'w', 'g'],\\n    'N': ['1', '2', '3'],\\n    'CS':['rc', 'rt', 'gc', 'gt', 'wt', 'ws'],\\n    'SAS':['cat', 'tas', 'cas'],\\n    'CAC':['raw', 'rag', 'wag'],\\n    'CSACS':['rtawt', 'wsagc', 'rcagt'],\\n    'NCS': ['1rs', '1wc', '1gt', '2wc', '1gc', '2ws'],\\n    'NCSANCS':['2rta2gc', '3rta3wt', '1wsa2gs', '2wta3gs']\\n}\\nall_basic_components = ['r', 'w', 'g', 't', 'c', 's', '1', '2', '3']\\nproblem_components = {\\n    't': ['t'],\\n    'c': ['c'],\\n    's': ['s'],\\n    'r': ['r'],\\n    'w': ['w'],\\n    'g': ['g'],\\n    '1': ['1'],\\n    '2': ['2'],\\n    '3': ['3'],\\n    'rc': ['r', 'c'],\\n    'rt': ['r', 't'],\\n    'gc': ['g', 'c'],\\n    'gt': ['g', 't'],\\n    'wt': ['w', 't'],\\n    'ws': ['w', 's'],\\n    'cat': ['c', 't'],\\n    'tas': ['t', 's'],\\n    'cas': ['c', 's'],\\n    'raw': ['r', 'w'],\\n    'rag': ['r', 'g'],\\n    'wag': ['w', 'g'],\\n    'rtawt': ['r', 't', 'w', 't'],\\n    'wsagc': ['w', 's', 'g', 'c'],\\n    'rcagt': ['r', 'c', 'g', 't'],\\n    '1rs': ['1', 'r', 's'],\\n    '1wc': ['1', 'w', 'c'],\\n    '1gt': ['1', 'g', 't'],\\n    '2wc': ['2', 'w', 'c'],\\n    '1gc': ['1', 'g', 'c'],\\n    '2ws': ['2', 'w', 's'],\\n    '2rta2gc': ['2', 'r', 't', '2', 'g', 'c'],\\n    '3rta3wt': ['3', 'r', 't', '3', 'w', 't'],\\n    '1wsa2gs': ['1', 'w', 's', '2', 'g', 's'],\\n    '2wta3gs': ['2', 'w', 't', '3', 'g', 's']\\n}\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_name = 'example_tree' #base name for saving files\n",
    "\n",
    "# all_concepts = ['S' ,'N', 'C', 'CS', 'SAS', 'CAC', 'CSACS', 'NCS', 'NCSANCS']\n",
    "# concept_problems = {\n",
    "#     'S': ['t', 'c', 's'],\n",
    "#     'C': ['r', 'w', 'g'],\n",
    "#     'N': ['1', '2', '3'],\n",
    "#     'CS':['rc', 'rt', 'gc', 'gt', 'wt', 'ws'],\n",
    "#     'SAS':['cat', 'tas', 'cas'],\n",
    "#     'CAC':['raw', 'rag', 'wag'],\n",
    "#     'CSACS':['rtawt', 'wsagc', 'rcagt'],\n",
    "#     'NCS': ['1rs', '1wc', '1gt', '2wc', '1gc', '2ws'],\n",
    "#     'NCSANCS':['2rta2gc', '3rta3wt', '1wsa2gs', '2wta3gs']\n",
    "# }\n",
    "# all_concepts = ['uninformed_search_basics','bfs','dfs','ids','informed_search_basics','ucs','ast','greedy','heuristic_admissibility','ast_optimality','hill_climbing','genetic','local_search_basics']\n",
    "# concept_problems = {\n",
    "#     'uninformed_search_basics': ['uninformed_search_basics_problem1'],\n",
    "#     'bfs': ['bfs_problem1'],\n",
    "#     'dfs': ['dfs_problem1'],\n",
    "#     'ids':['ids_problem1'],\n",
    "#     'informed_search_basics':['informed_search_basics_problem1'],\n",
    "#     'ucs':['ucs_problem1'],\n",
    "#     'ast':['ast_problem1'],\n",
    "#     'greedy': ['greedy_problem1'],\n",
    "#     'heuristic_admissibility':['heuristic_admissibility_problem1'],\n",
    "#     'ast_optimality': ['ast_optimality_problem1'],\n",
    "#     'hill_climbing': ['hill_climbing_problem1'],\n",
    "#     'genetic': ['genetic_problem1'],\n",
    "#     'local_search_basics': ['local_search_basics_problem1']\n",
    "# }\n",
    "\n",
    "# all_concepts = ['ai_intro_and_definitions','applications_of_ai','history_of_ai','logical_agents']\n",
    "# concept_problems = {\n",
    "#     'ai_intro_and_definitions': ['intro_p1','intro_p2','intro_p3','intro_p4','intro_p5'],\n",
    "#     'applications_of_ai': ['app_p1','app_p2','app_p3','app_p4','app_p5'],\n",
    "#     'history_of_ai': ['history_p1','history_p2','history_p3','history_p4','history_p5'],\n",
    "#     'logical_agents': ['logical_p1','logical_p2','logical_p3','logical_p4','logical_p5']\n",
    "# }\n",
    "# all_concepts = ['rational_agents', 'search']\n",
    "# concept_problems = {\n",
    "#     'rational_agents': ['rational_agents_p1','rational_agents_p2','rational_agents_p3','rational_agents_p4','rational_agents_p5'],\n",
    "#     'search': ['search_p1','search_p2','search_p3','search_p4','search_p5']\n",
    "# }\n",
    "# all_concepts = ['hello_world', 'operators','conditionals','collections','loops','functions','classes']\n",
    "# concept_problems = {\n",
    "#     'hello_world': ['hello_world_p1','hello_world_p2','hello_world_p3','hello_world_p4','hello_world_p5'],\n",
    "#     'operators': ['ops_p1'],\n",
    "#     'conditionals': ['conditionals_p1'],\n",
    "#     'collections': ['collections_p1'],\n",
    "#     'loops': ['loops_p1'],\n",
    "#     'functions': ['functions_p1'],\n",
    "#     'classes': ['classes_p1']\n",
    "    \n",
    "# }\n",
    "# all_concepts = ['definitions_and_examples','supervised_learning','unsupervised_learning','training_testing','validation','evaluation_metrics']\n",
    "# concept_problems = {\n",
    "#     'definitions_and_examples': ['definitions_and_examples_p1'],\n",
    "#     'supervised_learning': ['supervised_learning_p1'],\n",
    "#     'unsupervised_learning': ['unsupervised_learning_p1'],\n",
    "#     'training_testing': ['training_testing_p1'],\n",
    "#     'validation': ['validation_p1'],\n",
    "#     'evaluation_metrics': ['evaluation_p1']\n",
    "# }\n",
    "# all_concepts = ['neural_networks_intro','perceptron','xor_problem','deep_learning']\n",
    "# concept_problems = {\n",
    "#     'neural_networks_intro': ['neural_networks_intro_p1'],\n",
    "#     'perceptron': ['perceptron_p1'],\n",
    "#     'xor_problem': ['xor_problem_p1'],\n",
    "#     'deep_learning': ['deep_learning_p1']\n",
    "# }\n",
    "# all_concepts = ['ml_project']\n",
    "# concept_problems = {\n",
    "#     'ml_project': ['the_ml_project_problem']\n",
    "# }\n",
    "# all_concepts = ['ethical_ai','ai_potential']\n",
    "# concept_problems = {\n",
    "#     'ethical_ai': ['ethical_ai_p1'],\n",
    "#     'ai_potential': ['ai_potential_p1']\n",
    "# }\n",
    "# all_concepts = ['llms_and_chatgpt']\n",
    "# concept_problems = {\n",
    "#     'llms_and_chatgpt': ['llms_and_chatgpt_p1']\n",
    "# }\n",
    "\n",
    "\n",
    "# all_concepts = ['S','N','C','Z']\n",
    "# concept_problems = {\n",
    "#     'S': ['s'],\n",
    "#     'N': ['n'],\n",
    "#     'C': ['c'],\n",
    "#     'Z': ['z']\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_concepts = ['ai_intro_and_definitions','applications_of_ai','history_of_ai','logical_agents']\n",
    "all_concepts.extend(['rational_agents', 'search'])\n",
    "all_concepts.extend(['hello_world', 'operators','conditionals','collections','loops','functions','classes'])\n",
    "all_concepts.extend(['ml_definitions_and_examples','supervised_learning','unsupervised_learning','training_testing','validation','evaluation_metrics'])\n",
    "all_concepts.extend(['neural_networks_intro','perceptron','xor_problem','deep_learning'])\n",
    "all_concepts.extend(['ml_project'])\n",
    "all_concepts.extend(['ethical_ai','ai_potential'])\n",
    "all_concepts.extend(['llms_and_chatgpt'])\n",
    "all_concepts.extend(['congrats'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "concept_problems = {\n",
    "    'ai_intro_and_definitions': ['intro_p1','intro_p2','intro_p3','intro_p4','intro_p5'],\n",
    "    'applications_of_ai': ['app_p1','app_p2','app_p3','app_p4','app_p5'],\n",
    "    'history_of_ai': ['history_p1','history_p2','history_p3','history_p4','history_p5'],\n",
    "    'logical_agents': ['logical_p1','logical_p2','logical_p3','logical_p4','logical_p5'],\n",
    "\n",
    "    'rational_agents': ['rational_agents_p1','rational_agents_p2','rational_agents_p3','rational_agents_p4','rational_agents_p5'],\n",
    "    'search': ['search_p1','search_p2','search_p3','search_p4','search_p5'],\n",
    "    \n",
    "    'hello_world': ['hello_world_p1','hello_world_p2','hello_world_p3','hello_world_p4','hello_world_p5'],\n",
    "    'operators': ['ops_p1','ops_p2','ops_p3','ops_p4','ops_p5'],\n",
    "    'conditionals': ['conditionals_p1','conditionals_p2','conditionals_p3','conditionals_p4','conditionals_p5'],\n",
    "    'collections': ['collections_p1','collections_p2','collections_p3','collections_p4','collections_p5'],\n",
    "    'loops': ['loops_p1','loops_p2','loops_p3','loops_p4','loops_p5'],\n",
    "    'functions': ['functions_p1','functions_p2','functions_p3','functions_p4','functions_p5'],\n",
    "    'classes': ['classes_p1','classes_p2','classes_p3','classes_p4','classes_p5'],\n",
    "    \n",
    "    'ml_definitions_and_examples': ['ml_definitions_and_examples_p1','ml_definitions_and_examples_p2','ml_definitions_and_examples_p3','ml_definitions_and_examples_p4','ml_definitions_and_examples_p5'],\n",
    "    'supervised_learning': ['supervised_learning_p1','supervised_learning_p2','supervised_learning_p3','supervised_learning_p4','supervised_learning_p5'],\n",
    "    'unsupervised_learning': ['unsupervised_learning_p1','unsupervised_learning_p2','unsupervised_learning_p3','unsupervised_learning_p4','unsupervised_learning_p5'],\n",
    "    'training_testing': ['training_testing_p1','training_testing_p2','training_testing_p3','training_testing_p4','training_testing_p5'],\n",
    "    'validation': ['validation_p1','validation_p2','validation_p3','validation_p4','validation_p5'],\n",
    "    'evaluation_metrics': ['evaluation_p1','evaluation_p2','evaluation_p3','evaluation_p4','evaluation_p5'],\n",
    "    \n",
    "    'neural_networks_intro': ['neural_networks_intro_p1','neural_networks_intro_p2','neural_networks_intro_p3','neural_networks_intro_p4','neural_networks_intro_p5'],\n",
    "    'perceptron': ['perceptron_p1','perceptron_p2','perceptron_p3','perceptron_p4','perceptron_p5'],\n",
    "    'xor_problem': ['xor_problem_p1','xor_problem_p2','xor_problem_p3','xor_problem_p4','xor_problem_p5'],\n",
    "    'deep_learning': ['deep_learning_p1'],\n",
    "    \n",
    "    'ml_project': ['the_ml_project_problem'],\n",
    "    \n",
    "    'ethical_ai': ['ethical_ai_p1'],\n",
    "    'ai_potential': ['ai_potential_p1'],\n",
    "    \n",
    "    'llms_and_chatgpt': ['llms_and_chatgpt_p1'],\n",
    "\n",
    "    'congrats': ['congrats_finish_statement']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# all_basic_components = ['uninformed_search_basics_component','informed_search_basics_component','local_search_basics_component']\n",
    "# problem_components = {\n",
    "#     'uninformed_search_basics_problem1': ['uninformed_search_basics_component'],\n",
    "#     'informed_search_basics_problem1': ['informed_search_basics_component'],\n",
    "#     'local_search_basics_problem1': ['local_search_basics_component'],\n",
    "#     'bfs_problem1': ['uninformed_search_basics_component'],\n",
    "#     'dfs_problem1': ['uninformed_search_basics_component'],\n",
    "#     'ids_problem1': ['bfs_component','dfs_component'],\n",
    "#     'ucs_problem1': ['ids_component','informed_search_basics_component'],\n",
    "#     'greedy_problem1': ['ucs_component'],\n",
    "#     'ast_problem1': ['greedy_component'],\n",
    "#     'heuristic_admissibility_problem1': ['ast_component'],\n",
    "#     'ast_optimality_problem1': ['ast__component'],\n",
    "#     'hill_climbing_problem1': ['local_search_basics_component'],\n",
    "#     'genetic_problem1': ['local_search_basics_component']\n",
    "# }\n",
    "all_basic_components = None\n",
    "problem_components = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "all_concepts = ['S' ,'N', 'C', 'CS', 'SAS', 'CAC', 'CSACS', 'NCS', 'NCSANCS']\n",
    "concept_problems = {\n",
    "    'S': ['t', 'c', 's'],\n",
    "    'C': ['r', 'w', 'g'],\n",
    "    'N': ['1', '2', '3'],\n",
    "    'CS':['rc', 'rt', 'gc', 'gt', 'wt', 'ws'],\n",
    "    'SAS':['cat', 'tas', 'cas'],\n",
    "    'CAC':['raw', 'rag', 'wag'],\n",
    "    'CSACS':['rtawt', 'wsagc', 'rcagt'],\n",
    "    'NCS': ['1rs', '1wc', '1gt', '2wc', '1gc', '2ws'],\n",
    "    'NCSANCS':['2rta2gc', '3rta3wt', '1wsa2gs', '2wta3gs']\n",
    "}\n",
    "all_basic_components = ['r', 'w', 'g', 't', 'c', 's', '1', '2', '3']\n",
    "problem_components = {\n",
    "    't': ['t'],\n",
    "    'c': ['c'],\n",
    "    's': ['s'],\n",
    "    'r': ['r'],\n",
    "    'w': ['w'],\n",
    "    'g': ['g'],\n",
    "    '1': ['1'],\n",
    "    '2': ['2'],\n",
    "    '3': ['3'],\n",
    "    'rc': ['r', 'c'],\n",
    "    'rt': ['r', 't'],\n",
    "    'gc': ['g', 'c'],\n",
    "    'gt': ['g', 't'],\n",
    "    'wt': ['w', 't'],\n",
    "    'ws': ['w', 's'],\n",
    "    'cat': ['c', 't'],\n",
    "    'tas': ['t', 's'],\n",
    "    'cas': ['c', 's'],\n",
    "    'raw': ['r', 'w'],\n",
    "    'rag': ['r', 'g'],\n",
    "    'wag': ['w', 'g'],\n",
    "    'rtawt': ['r', 't', 'w', 't'],\n",
    "    'wsagc': ['w', 's', 'g', 'c'],\n",
    "    'rcagt': ['r', 'c', 'g', 't'],\n",
    "    '1rs': ['1', 'r', 's'],\n",
    "    '1wc': ['1', 'w', 'c'],\n",
    "    '1gt': ['1', 'g', 't'],\n",
    "    '2wc': ['2', 'w', 'c'],\n",
    "    '1gc': ['1', 'g', 'c'],\n",
    "    '2ws': ['2', 'w', 's'],\n",
    "    '2rta2gc': ['2', 'r', 't', '2', 'g', 'c'],\n",
    "    '3rta3wt': ['3', 'r', 't', '3', 'w', 't'],\n",
    "    '1wsa2gs': ['1', 'w', 's', '2', 'g', 's'],\n",
    "    '2wta3gs': ['2', 'w', 't', '3', 'g', 's']\n",
    "}\n",
    "'''\n",
    "\n",
    "# all_basic_components = None\n",
    "# problem_components = None\n",
    "\n",
    "# if problem_components is None or all_basic_components is None:\n",
    "#     problem_components = {}\n",
    "#     for concept, concept_problems_list in concept_problems.items():\n",
    "#         for problem in concept_problems_list:\n",
    "#             problem_components[problem] = [problem]\n",
    "#     all_basic_components = list(problem_components.keys())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tree_structure = {\n",
    "#     'Root': ['S', 'N', 'C'],\n",
    "#     'S': ['CS', 'SAS'],\n",
    "#     'N': ['NCS'],\n",
    "#     'C': ['CS', 'CAC'],\n",
    "#     'CS': ['CSACS', 'NCS'],\n",
    "#     'SAS': ['CSACS'],\n",
    "#     'CAC': ['CSACS'],\n",
    "#     'CSACS': ['NCSANCS'],\n",
    "#     'NCS': ['NCSANCS'],\n",
    "#     'NCSANCS': []\n",
    "# }\n",
    "\n",
    "# tree_structure = {\n",
    "#     'Root': ['S', 'N', 'C'],\n",
    "#     'S': ['Z'],\n",
    "#     'N': ['Z'],\n",
    "#     'C': ['Z'],\n",
    "#     'Z': []\n",
    "# }\n",
    "\n",
    "\n",
    "'''\n",
    "tree_structure = {\n",
    "    'Root': ['ai_intro_and_definitions'],\n",
    "    'ai_intro_and_definitions': ['applications_of_ai','history_of_ai','logical_agents'],\n",
    "    'applications_of_ai': ['rational_agents','hello_world'],\n",
    "    'history_of_ai': ['rational_agents','hello_world'],\n",
    "    'logical_agents': ['rational_agents','hello_world'],\n",
    "    \n",
    "    'rational_agents': ['search'],\n",
    "    'search': ['ml_definitions_and_examples'],\n",
    "    \n",
    "    'hello_world': ['operators'],\n",
    "    'operators': ['conditionals'],\n",
    "    'conditionals': ['loops'],\n",
    "    'loops': ['functions','collections'],\n",
    "    'collections': ['ml_definitions_and_examples'],\n",
    "    'functions': ['classes'],\n",
    "    'classes': ['ml_definitions_and_examples'],\n",
    "\n",
    "    \n",
    "    'ml_definitions_and_examples': ['supervised_learning','unsupervised_learning'],\n",
    "    'supervised_learning': ['training_testing'],\n",
    "    'unsupervised_learning': ['training_testing'],\n",
    "    'training_testing': ['validation', 'evaluation_metrics','ethical_ai'],\n",
    "    'validation': ['neural_networks_intro'],\n",
    "    'evaluation_metrics': ['neural_networks_intro','ethical_ai'],\n",
    "\n",
    "    \n",
    "    'neural_networks_intro': ['perceptron'],\n",
    "    'perceptron': ['xor_problem'],\n",
    "    'xor_problem': ['deep_learning'],\n",
    "    'deep_learning': ['ml_project'],\n",
    "\n",
    "                      \n",
    "    'ml_project': ['congrats'],\n",
    "\n",
    "    'ethical_ai': ['ai_potential'],\n",
    "    'ai_potential': ['llms_and_chatgpt'],\n",
    "\n",
    "    \n",
    "    'llms_and_chatgpt': ['congrats'],\n",
    "\n",
    "    'congrats': []\n",
    "}\n",
    "'''\n",
    "\n",
    "\n",
    "all_basic_components = None\n",
    "problem_components = None\n",
    "\n",
    "# # Initialize stack of concepts in the frontier excluding the root\n",
    "# st = []\n",
    "# for concept in tree_structure['Root']:\n",
    "#     st.append((concept,set()))\n",
    "\n",
    "# # Initialize all problems to sets only containing the current concept\n",
    "# problem_components = {}\n",
    "# for concept, concept_problems_list in concept_problems.items():\n",
    "#     for problem in concept_problems_list:\n",
    "#         problem_components[problem] = set([concept])\n",
    "\n",
    "\n",
    "# while len(st) > 0:\n",
    "#     curConcept, prev_parents = st.pop()\n",
    "\n",
    "#     prev_parents = copy.deepcopy(prev_parents)\n",
    "\n",
    "#     # Add this concept to the list of requirements\n",
    "#     prev_parents.add(curConcept)\n",
    "\n",
    "#     # Add previous concepts and this curConcept\n",
    "#     for problem in concept_problems[curConcept]: # concept -> problem list\n",
    "#         for prevConcept in prev_parents: # for all previous parents we've traversed\n",
    "#             problem_components[problem].add(prevConcept)\n",
    "\n",
    "    \n",
    "#     # Add children to the stack\n",
    "#     for concept in tree_structure[curConcept]:\n",
    "#         st.append((concept,prev_parents))\n",
    "\n",
    "\n",
    "# # Make the sets into lists\n",
    "# for problem in problem_components:\n",
    "#     problem_components[problem] = list(problem_components[problem])\n",
    "\n",
    "# all_basic_components = set()\n",
    "# for problem in problem_components:\n",
    "#     for component in problem_components[problem]:\n",
    "#         all_basic_components.add(component)\n",
    "# all_basic_components = list(all_basic_components)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "if problem_components is None or all_basic_components is None:\n",
    "    problem_components = {}\n",
    "    for concept, concept_problems_list in concept_problems.items():\n",
    "        for problem in concept_problems_list:\n",
    "            problem_components[problem] = [problem]\n",
    "    all_basic_components = list(problem_components.keys())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intro_p1': ['intro_p1'], 'intro_p2': ['intro_p2'], 'intro_p3': ['intro_p3'], 'intro_p4': ['intro_p4'], 'intro_p5': ['intro_p5'], 'app_p1': ['app_p1'], 'app_p2': ['app_p2'], 'app_p3': ['app_p3'], 'app_p4': ['app_p4'], 'app_p5': ['app_p5'], 'history_p1': ['history_p1'], 'history_p2': ['history_p2'], 'history_p3': ['history_p3'], 'history_p4': ['history_p4'], 'history_p5': ['history_p5'], 'logical_p1': ['logical_p1'], 'logical_p2': ['logical_p2'], 'logical_p3': ['logical_p3'], 'logical_p4': ['logical_p4'], 'logical_p5': ['logical_p5'], 'rational_agents_p1': ['rational_agents_p1'], 'rational_agents_p2': ['rational_agents_p2'], 'rational_agents_p3': ['rational_agents_p3'], 'rational_agents_p4': ['rational_agents_p4'], 'rational_agents_p5': ['rational_agents_p5'], 'search_p1': ['search_p1'], 'search_p2': ['search_p2'], 'search_p3': ['search_p3'], 'search_p4': ['search_p4'], 'search_p5': ['search_p5'], 'hello_world_p1': ['hello_world_p1'], 'hello_world_p2': ['hello_world_p2'], 'hello_world_p3': ['hello_world_p3'], 'hello_world_p4': ['hello_world_p4'], 'hello_world_p5': ['hello_world_p5'], 'ops_p1': ['ops_p1'], 'ops_p2': ['ops_p2'], 'ops_p3': ['ops_p3'], 'ops_p4': ['ops_p4'], 'ops_p5': ['ops_p5'], 'conditionals_p1': ['conditionals_p1'], 'conditionals_p2': ['conditionals_p2'], 'conditionals_p3': ['conditionals_p3'], 'conditionals_p4': ['conditionals_p4'], 'conditionals_p5': ['conditionals_p5'], 'collections_p1': ['collections_p1'], 'collections_p2': ['collections_p2'], 'collections_p3': ['collections_p3'], 'collections_p4': ['collections_p4'], 'collections_p5': ['collections_p5'], 'loops_p1': ['loops_p1'], 'loops_p2': ['loops_p2'], 'loops_p3': ['loops_p3'], 'loops_p4': ['loops_p4'], 'loops_p5': ['loops_p5'], 'functions_p1': ['functions_p1'], 'functions_p2': ['functions_p2'], 'functions_p3': ['functions_p3'], 'functions_p4': ['functions_p4'], 'functions_p5': ['functions_p5'], 'classes_p1': ['classes_p1'], 'classes_p2': ['classes_p2'], 'classes_p3': ['classes_p3'], 'classes_p4': ['classes_p4'], 'classes_p5': ['classes_p5'], 'ml_definitions_and_examples_p1': ['ml_definitions_and_examples_p1'], 'ml_definitions_and_examples_p2': ['ml_definitions_and_examples_p2'], 'ml_definitions_and_examples_p3': ['ml_definitions_and_examples_p3'], 'ml_definitions_and_examples_p4': ['ml_definitions_and_examples_p4'], 'ml_definitions_and_examples_p5': ['ml_definitions_and_examples_p5'], 'supervised_learning_p1': ['supervised_learning_p1'], 'supervised_learning_p2': ['supervised_learning_p2'], 'supervised_learning_p3': ['supervised_learning_p3'], 'supervised_learning_p4': ['supervised_learning_p4'], 'supervised_learning_p5': ['supervised_learning_p5'], 'unsupervised_learning_p1': ['unsupervised_learning_p1'], 'unsupervised_learning_p2': ['unsupervised_learning_p2'], 'unsupervised_learning_p3': ['unsupervised_learning_p3'], 'unsupervised_learning_p4': ['unsupervised_learning_p4'], 'unsupervised_learning_p5': ['unsupervised_learning_p5'], 'training_testing_p1': ['training_testing_p1'], 'training_testing_p2': ['training_testing_p2'], 'training_testing_p3': ['training_testing_p3'], 'training_testing_p4': ['training_testing_p4'], 'training_testing_p5': ['training_testing_p5'], 'validation_p1': ['validation_p1'], 'validation_p2': ['validation_p2'], 'validation_p3': ['validation_p3'], 'validation_p4': ['validation_p4'], 'validation_p5': ['validation_p5'], 'evaluation_p1': ['evaluation_p1'], 'evaluation_p2': ['evaluation_p2'], 'evaluation_p3': ['evaluation_p3'], 'evaluation_p4': ['evaluation_p4'], 'evaluation_p5': ['evaluation_p5'], 'neural_networks_intro_p1': ['neural_networks_intro_p1'], 'neural_networks_intro_p2': ['neural_networks_intro_p2'], 'neural_networks_intro_p3': ['neural_networks_intro_p3'], 'neural_networks_intro_p4': ['neural_networks_intro_p4'], 'neural_networks_intro_p5': ['neural_networks_intro_p5'], 'perceptron_p1': ['perceptron_p1'], 'perceptron_p2': ['perceptron_p2'], 'perceptron_p3': ['perceptron_p3'], 'perceptron_p4': ['perceptron_p4'], 'perceptron_p5': ['perceptron_p5'], 'xor_problem_p1': ['xor_problem_p1'], 'xor_problem_p2': ['xor_problem_p2'], 'xor_problem_p3': ['xor_problem_p3'], 'xor_problem_p4': ['xor_problem_p4'], 'xor_problem_p5': ['xor_problem_p5'], 'deep_learning_p1': ['deep_learning_p1'], 'the_ml_project_problem': ['the_ml_project_problem'], 'ethical_ai_p1': ['ethical_ai_p1'], 'ai_potential_p1': ['ai_potential_p1'], 'llms_and_chatgpt_p1': ['llms_and_chatgpt_p1'], 'congrats_finish_statement': ['congrats_finish_statement']}\n"
     ]
    }
   ],
   "source": [
    "print(problem_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using Build_Tree and trace based analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Parameters\n",
    "n = 1 #the n for creating in ngrams, in our case we are using 1-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The Build_Tree tree needs a Build_Tree_Data object that takes in all_concepts, concept_problems, all_basic_components, problem_components and n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = Build_Tree_Data(all_concepts= all_concepts, concept_problems = concept_problems, \n",
    "                       all_basic_components = all_basic_components, problem_components = problem_components, n = n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Build_Tree additionally takes in a comparison function (the ```comp_func``` argument). This function must be defined in the file 'compare_function.py' (this necessity is for saving and loading the tree using the pickle package) and should take in node1, node2 and return \n",
    "- -1 if node1 is harder than node2\n",
    "- 1 if node2 is harder than node1\n",
    "- 0 if neither is harder than the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Tree\n",
      "Current concept: 0, Current concept Name: ai_intro_and_definitions\n",
      "Current concept: 1, Current concept Name: applications_of_ai\n",
      "Current concept: 2, Current concept Name: history_of_ai\n",
      "Current concept: 3, Current concept Name: logical_agents\n",
      "Current concept: 4, Current concept Name: rational_agents\n",
      "Current concept: 5, Current concept Name: search\n",
      "Current concept: 6, Current concept Name: hello_world\n",
      "Current concept: 7, Current concept Name: operators\n",
      "Current concept: 8, Current concept Name: conditionals\n",
      "Current concept: 9, Current concept Name: collections\n",
      "Current concept: 10, Current concept Name: loops\n",
      "Current concept: 11, Current concept Name: functions\n",
      "Current concept: 12, Current concept Name: classes\n",
      "Current concept: 13, Current concept Name: ml_definitions_and_examples\n",
      "Current concept: 14, Current concept Name: supervised_learning\n",
      "Current concept: 15, Current concept Name: unsupervised_learning\n",
      "Current concept: 16, Current concept Name: training_testing\n",
      "Current concept: 17, Current concept Name: validation\n",
      "Current concept: 18, Current concept Name: evaluation_metrics\n",
      "Current concept: 19, Current concept Name: neural_networks_intro\n",
      "Current concept: 20, Current concept Name: perceptron\n",
      "Current concept: 21, Current concept Name: xor_problem\n",
      "Current concept: 22, Current concept Name: deep_learning\n",
      "Current concept: 23, Current concept Name: ml_project\n",
      "Current concept: 24, Current concept Name: ethical_ai\n",
      "Current concept: 25, Current concept Name: ai_potential\n",
      "Current concept: 26, Current concept Name: llms_and_chatgpt\n",
      "Current concept: 27, Current concept Name: congrats\n"
     ]
    }
   ],
   "source": [
    "print('Creating Tree')\n",
    "\n",
    "#Define the \"Root\" tree\n",
    "progression_tree_build = Build_Tree(name='Root', data=data, comp_func=compare_ngrams)\n",
    "\n",
    "#Loop through each concept in all_concepts and insert it into the tree\n",
    "for i, concept_name in enumerate(all_concepts):\n",
    "    print('Current concept: %d, Current concept Name: %s'%(i, concept_name))\n",
    "    progression_tree_build.insert_node(concept_name)\n",
    "\n",
    "#calculate ancestors (prerequisites) after all nodes are inserted\n",
    "progression_tree_build.calculate_parents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Save the tree, this will save the tree as 'tree_name.p'\n",
    "progression_tree_build.save_tree(tree_name + '.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using and Static_Tree a predefined tree structure to build a tree\n",
    "\n",
    "Static tree takes in the predefined structure in the form of a dictionary mapping concept to all immediate children (all problems directly easier than it) in the prerequisite graph. See the ```tree_structure``` below for our example. Note that the 'Root' node must be defined.\n",
    "\n",
    "Similarly to Build_Tree it also takes in all_concepts, concept_problems, all_basic_components, and problem_components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tree_structure = {\n",
    "#     'Root': ['uninformed_search_basics', 'local_search_basics'],\n",
    "#     'uninformed_search_basics': ['bfs', 'dfs'],\n",
    "#     'informed_search_basics': ['greedy','ast'],\n",
    "#     'local_search_basics': ['genetic','hill_climbing'],\n",
    "#     'bfs': ['ids'],\n",
    "#     'dfs': ['ids'],\n",
    "#     'ids': ['ucs'],\n",
    "#     'ucs': ['informed_search_basics'],\n",
    "#     'greedy': ['heuristic_admissibility'],\n",
    "#     'ast': ['heuristic_admissibility','ast_optimality'],\n",
    "#     'heuristic_admissibility': [],\n",
    "#     'ast_optimality': [],\n",
    "#     'genetic': [],\n",
    "#     'hill_climbing': []\n",
    "# }\n",
    "\n",
    "# tree_structure = {\n",
    "#     'Root': ['ai_intro_and_definitions'],\n",
    "#     'ai_intro_and_definitions': ['applications_of_ai','history_of_ai','logical_agents'],\n",
    "#     'applications_of_ai': [],\n",
    "#     'history_of_ai': [],\n",
    "#     'logical_agents': []\n",
    "# }\n",
    "\n",
    "# tree_structure = {\n",
    "#     'Root': ['rational_agents'],\n",
    "#     'rational_agents': ['search'],\n",
    "#     'search': []\n",
    "# }\n",
    "\n",
    "# tree_structure = {\n",
    "#     'Root': ['hello_world'],\n",
    "#     'hello_world': ['operators'],\n",
    "#     'operators': ['conditionals'],\n",
    "#     'conditionals': ['loops'],\n",
    "#     'loops': ['functions','collections'],\n",
    "#     'collections': [],\n",
    "#     'functions': ['classes'],\n",
    "#     'classes': []\n",
    "# }\n",
    "# tree_structure = {\n",
    "#     'Root': ['ml_definitions_and_examples'],\n",
    "#     'ml_definitions_and_examples': ['supervised_learning','unsupervised_learning'],\n",
    "#     'supervised_learning': ['training_testing'],\n",
    "#     'unsupervised_learning': ['training_testing'],\n",
    "#     'training_testing': ['validation', 'evaluation_metrics'],\n",
    "#     'validation': [],\n",
    "#     'evaluation_metrics': []\n",
    "# }\n",
    "# tree_structure = {\n",
    "#     'Root': ['neural_networks_intro'],\n",
    "#     'neural_networks_intro': ['perceptron'],\n",
    "#     'perceptron': ['xor_problem'],\n",
    "#     'xor_problem': ['deep_learning'],\n",
    "#     'deep_learning': []\n",
    "# }\n",
    "\n",
    "# tree_structure = {\n",
    "#     'Root': ['ml_project'],\n",
    "#     'ml_project': []\n",
    "# }\n",
    "# tree_structure = {\n",
    "#     'Root': ['ethical_ai'],\n",
    "#     'ethical_ai': ['ai_potential'],\n",
    "#     'ai_potential': []\n",
    "# }\n",
    "# tree_structure = {\n",
    "#     'Root': ['llms_and_chatgpt'],\n",
    "#     'llms_and_chatgpt': []\n",
    "# }\n",
    "\n",
    "\n",
    "# tree_structure = {\n",
    "#     'Root': ['uninformed_search_basics', 'local_search_basics'],\n",
    "#     'uninformed_search_basics': ['bfs', 'dfs'],\n",
    "#     'informed_search_basics': ['greedy','ast'],\n",
    "#     'local_search_basics': ['genetic','hill_climbing'],\n",
    "#     'bfs': ['ids'],\n",
    "#     'dfs': ['ids'],\n",
    "#     'ids': ['ucs'],\n",
    "#     'ucs': ['informed_search_basics'],\n",
    "#     'greedy': ['heuristic_admissibility'],\n",
    "#     'ast': ['heuristic_admissibility','ast_optimality'],\n",
    "#     'heuristic_admissibility': [],\n",
    "#     'ast_optimality': [],\n",
    "#     'genetic': [],\n",
    "#     'hill_climbing': []\n",
    "# }\n",
    "\n",
    "# tree_structure = {\n",
    "#     'Root': ['S', 'N', 'C'],\n",
    "#     'S': ['CS', 'SAS'],\n",
    "#     'N': ['NCS'],\n",
    "#     'C': ['CS', 'CAC'],\n",
    "#     'CS': ['CSACS', 'NCS'],\n",
    "#     'SAS': ['CSACS'],\n",
    "#     'CAC': ['CSACS'],\n",
    "#     'CSACS': ['NCSANCS'],\n",
    "#     'NCS': ['NCSANCS'],\n",
    "#     'NCSANCS': []\n",
    "# }\n",
    "\n",
    "\n",
    "tree_structure = {\n",
    "    'Root': ['ai_intro_and_definitions'],\n",
    "    'ai_intro_and_definitions': ['applications_of_ai','history_of_ai','logical_agents'],\n",
    "    'applications_of_ai': ['rational_agents','hello_world'],\n",
    "    'history_of_ai': ['rational_agents','hello_world'],\n",
    "    'logical_agents': ['rational_agents','hello_world'],\n",
    "    \n",
    "    'rational_agents': ['search'],\n",
    "    'search': ['ml_definitions_and_examples'],\n",
    "    \n",
    "    'hello_world': ['operators'],\n",
    "    'operators': ['conditionals'],\n",
    "    'conditionals': ['loops'],\n",
    "    'loops': ['functions','collections'],\n",
    "    'collections': ['ml_definitions_and_examples'],\n",
    "    'functions': ['classes'],\n",
    "    'classes': ['ml_definitions_and_examples'],\n",
    "\n",
    "    \n",
    "    'ml_definitions_and_examples': ['supervised_learning','unsupervised_learning'],\n",
    "    'supervised_learning': ['training_testing'],\n",
    "    'unsupervised_learning': ['training_testing'],\n",
    "    'training_testing': ['validation', 'evaluation_metrics','ethical_ai'],\n",
    "    'validation': ['neural_networks_intro'],\n",
    "    'evaluation_metrics': ['neural_networks_intro','ethical_ai'],\n",
    "\n",
    "    \n",
    "    'neural_networks_intro': ['perceptron'],\n",
    "    'perceptron': ['xor_problem'],\n",
    "    'xor_problem': ['deep_learning'],\n",
    "    'deep_learning': ['ml_project'],\n",
    "\n",
    "                      \n",
    "    'ml_project': ['congrats'],\n",
    "\n",
    "    'ethical_ai': ['ai_potential'],\n",
    "    'ai_potential': ['llms_and_chatgpt'],\n",
    "\n",
    "    \n",
    "    'llms_and_chatgpt': ['congrats'],\n",
    "\n",
    "    'congrats': []\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using and Static_Tree a predefined tree structure to build a tree\n",
    "\n",
    "Static tree takes in the predefined structure in the form of a dictionary mapping concept to all immediate children (all problems directly easier than it) in the prerequisite graph. See the ```tree_structure``` below for our example. Note that the 'Root' node must be defined.\n",
    "\n",
    "Similarly to Build_Tree it also takes in all_concepts, concept_problems, all_basic_components, and problem_components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntree_structure = {\\n    'Root': ['ai_intro_and_definitions'],\\n    'ai_intro_and_definitions': ['applications_of_ai','history_of_ai','logical_agents'],\\n    'applications_of_ai': ['rational_agents','hello_world'],\\n    'history_of_ai': ['rational_agents','hello_world'],\\n    'logical_agents': ['rational_agents','hello_world'],\\n    \\n    'rational_agents': ['search'],\\n    'search': ['ml_definitions_and_examples'],\\n    \\n    'hello_world': ['operators'],\\n    'operators': ['conditionals'],\\n    'conditionals': ['loops'],\\n    'loops': ['functions','collections'],\\n    'collections': ['ml_definitions_and_examples'],\\n    'functions': ['classes'],\\n    'classes': ['ml_definitions_and_examples'],\\n\\n    \\n    'ml_definitions_and_examples': ['supervised_learning','unsupervised_learning'],\\n    'supervised_learning': ['training_testing'],\\n    'unsupervised_learning': ['training_testing'],\\n    'training_testing': ['validation', 'evaluation_metrics','ethical_ai'],\\n    'validation': ['neural_networks_intro'],\\n    'evaluation_metrics': ['neural_networks_intro','ethical_ai'],\\n\\n    \\n    'neural_networks_intro': ['perceptron'],\\n    'perceptron': ['xor_problem'],\\n    'xor_problem': ['deep_learning'],\\n    'deep_learning': ['ml_project'],\\n\\n                      \\n    'ml_project': ['congrats'],\\n\\n    'ethical_ai': ['ai_potential'],\\n    'ai_potential': ['llms_and_chatgpt'],\\n\\n    \\n    'llms_and_chatgpt': ['congrats'],\\n\\n    'congrats': []\\n}\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tree_structure = {\n",
    "#     'Root': ['uninformed_search_basics', 'local_search_basics'],\n",
    "#     'uninformed_search_basics': ['bfs', 'dfs'],\n",
    "#     'informed_search_basics': ['greedy','ast'],\n",
    "#     'local_search_basics': ['genetic','hill_climbing'],\n",
    "#     'bfs': ['ids'],\n",
    "#     'dfs': ['ids'],\n",
    "#     'ids': ['ucs'],\n",
    "#     'ucs': ['informed_search_basics'],\n",
    "#     'greedy': ['heuristic_admissibility'],\n",
    "#     'ast': ['heuristic_admissibility','ast_optimality'],\n",
    "#     'heuristic_admissibility': [],\n",
    "#     'ast_optimality': [],\n",
    "#     'genetic': [],\n",
    "#     'hill_climbing': []\n",
    "# }\n",
    "\n",
    "# tree_structure = {\n",
    "#     'Root': ['ai_intro_and_definitions'],\n",
    "#     'ai_intro_and_definitions': ['applications_of_ai','history_of_ai','logical_agents'],\n",
    "#     'applications_of_ai': [],\n",
    "#     'history_of_ai': [],\n",
    "#     'logical_agents': []\n",
    "# }\n",
    "\n",
    "# tree_structure = {\n",
    "#     'Root': ['rational_agents'],\n",
    "#     'rational_agents': ['search'],\n",
    "#     'search': []\n",
    "# }\n",
    "\n",
    "# tree_structure = {\n",
    "#     'Root': ['hello_world'],\n",
    "#     'hello_world': ['operators'],\n",
    "#     'operators': ['conditionals'],\n",
    "#     'conditionals': ['loops'],\n",
    "#     'loops': ['functions','collections'],\n",
    "#     'collections': [],\n",
    "#     'functions': ['classes'],\n",
    "#     'classes': []\n",
    "# }\n",
    "# tree_structure = {\n",
    "#     'Root': ['ml_definitions_and_examples'],\n",
    "#     'ml_definitions_and_examples': ['supervised_learning','unsupervised_learning'],\n",
    "#     'supervised_learning': ['training_testing'],\n",
    "#     'unsupervised_learning': ['training_testing'],\n",
    "#     'training_testing': ['validation', 'evaluation_metrics'],\n",
    "#     'validation': [],\n",
    "#     'evaluation_metrics': []\n",
    "# }\n",
    "# tree_structure = {\n",
    "#     'Root': ['neural_networks_intro'],\n",
    "#     'neural_networks_intro': ['perceptron'],\n",
    "#     'perceptron': ['xor_problem'],\n",
    "#     'xor_problem': ['deep_learning'],\n",
    "#     'deep_learning': []\n",
    "# }\n",
    "\n",
    "# tree_structure = {\n",
    "#     'Root': ['ml_project'],\n",
    "#     'ml_project': []\n",
    "# }\n",
    "# tree_structure = {\n",
    "#     'Root': ['ethical_ai'],\n",
    "#     'ethical_ai': ['ai_potential'],\n",
    "#     'ai_potential': []\n",
    "# }\n",
    "# tree_structure = {\n",
    "#     'Root': ['llms_and_chatgpt'],\n",
    "#     'llms_and_chatgpt': []\n",
    "# }\n",
    "\n",
    "\n",
    "# tree_structure = {\n",
    "#     'Root': ['uninformed_search_basics', 'local_search_basics'],\n",
    "#     'uninformed_search_basics': ['bfs', 'dfs'],\n",
    "#     'informed_search_basics': ['greedy','ast'],\n",
    "#     'local_search_basics': ['genetic','hill_climbing'],\n",
    "#     'bfs': ['ids'],\n",
    "#     'dfs': ['ids'],\n",
    "#     'ids': ['ucs'],\n",
    "#     'ucs': ['informed_search_basics'],\n",
    "#     'greedy': ['heuristic_admissibility'],\n",
    "#     'ast': ['heuristic_admissibility','ast_optimality'],\n",
    "#     'heuristic_admissibility': [],\n",
    "#     'ast_optimality': [],\n",
    "#     'genetic': [],\n",
    "#     'hill_climbing': []\n",
    "# }\n",
    "\n",
    "# tree_structure = {\n",
    "#     'Root': ['S', 'N', 'C'],\n",
    "#     'S': ['CS', 'SAS'],\n",
    "#     'N': ['NCS'],\n",
    "#     'C': ['CS', 'CAC'],\n",
    "#     'CS': ['CSACS', 'NCS'],\n",
    "#     'SAS': ['CSACS'],\n",
    "#     'CAC': ['CSACS'],\n",
    "#     'CSACS': ['NCSANCS'],\n",
    "#     'NCS': ['NCSANCS'],\n",
    "#     'NCSANCS': []\n",
    "# }\n",
    "\n",
    "'''\n",
    "tree_structure = {\n",
    "    'Root': ['ai_intro_and_definitions'],\n",
    "    'ai_intro_and_definitions': ['applications_of_ai','history_of_ai','logical_agents'],\n",
    "    'applications_of_ai': ['rational_agents','hello_world'],\n",
    "    'history_of_ai': ['rational_agents','hello_world'],\n",
    "    'logical_agents': ['rational_agents','hello_world'],\n",
    "    \n",
    "    'rational_agents': ['search'],\n",
    "    'search': ['ml_definitions_and_examples'],\n",
    "    \n",
    "    'hello_world': ['operators'],\n",
    "    'operators': ['conditionals'],\n",
    "    'conditionals': ['loops'],\n",
    "    'loops': ['functions','collections'],\n",
    "    'collections': ['ml_definitions_and_examples'],\n",
    "    'functions': ['classes'],\n",
    "    'classes': ['ml_definitions_and_examples'],\n",
    "\n",
    "    \n",
    "    'ml_definitions_and_examples': ['supervised_learning','unsupervised_learning'],\n",
    "    'supervised_learning': ['training_testing'],\n",
    "    'unsupervised_learning': ['training_testing'],\n",
    "    'training_testing': ['validation', 'evaluation_metrics','ethical_ai'],\n",
    "    'validation': ['neural_networks_intro'],\n",
    "    'evaluation_metrics': ['neural_networks_intro','ethical_ai'],\n",
    "\n",
    "    \n",
    "    'neural_networks_intro': ['perceptron'],\n",
    "    'perceptron': ['xor_problem'],\n",
    "    'xor_problem': ['deep_learning'],\n",
    "    'deep_learning': ['ml_project'],\n",
    "\n",
    "                      \n",
    "    'ml_project': ['congrats'],\n",
    "\n",
    "    'ethical_ai': ['ai_potential'],\n",
    "    'ai_potential': ['llms_and_chatgpt'],\n",
    "\n",
    "    \n",
    "    'llms_and_chatgpt': ['congrats'],\n",
    "\n",
    "    'congrats': []\n",
    "}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Create the tree\n",
    "progression_tree_static = Static_Tree(children = tree_structure, all_concepts = all_concepts, \n",
    "                                      concept_problems = concept_problems, all_basic_components = all_basic_components, \n",
    "                                      problem_components = problem_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#save the tree, this will save the tree to a file 'tree_name.txt'\n",
    "progression_tree_static.save_tree(tree_name + '.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Other Tree Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualizing the curriculum graph made by Build_Tree using the Digraph package\n",
    "The following code will make a visualization of the graph made by Build_Tree - will also save the graph as '```tree_name```.gv' and a visualization of the graph as '```tree_name```.gv.png' in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Some helpful functions for rendering and visualizing and saving graphs with the Digraph package\n",
    "def create_graph (tree, data):\n",
    "    graph = Digraph(format='png', strict = True)\n",
    "    for problem_name, problem_data in data.items():\n",
    "        graph.node(problem_name, problem_data)\n",
    "        tree.add_edges_to_progression(graph)\n",
    "    return graph\n",
    "\n",
    "def render_save_graph(graph, save_name):\n",
    "    graph.render(save_name, view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Choose a tree to use\n",
    "# progression_tree = progression_tree_build\n",
    "progression_tree = progression_tree_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Visualize and save the graph\n",
    "concept_names = {concept:concept for concept in all_concepts}\n",
    "progression_graph = create_graph(progression_tree, concept_names)\n",
    "render_save_graph(progression_graph, tree_name + '.gv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading in the trees from file\n",
    "To saved trees can be loaded in from the their save files in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "progression_tree_build_2 = Build_Tree(tree_filename = tree_name + '.p')\n",
    "progression_tree_static_2 = Static_Tree(tree_filename = tree_name + '.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Getting additional information:\n",
    "Additionally we can get the immediate children and parents as well as all the children and parents from a tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Children: {'Root': ['ai_intro_and_definitions', 'history_of_ai', 'search', 'hello_world', 'operators', 'conditionals', 'collections', 'loops', 'functions', 'classes', 'training_testing', 'validation', 'neural_networks_intro', 'perceptron', 'xor_problem', 'deep_learning', 'ml_project', 'ethical_ai', 'ai_potential', 'llms_and_chatgpt', 'congrats'], 'ai_intro_and_definitions': [], 'applications_of_ai': [], 'history_of_ai': [], 'logical_agents': [], 'rational_agents': [], 'search': [], 'hello_world': [], 'operators': [], 'conditionals': [], 'collections': ['logical_agents', 'evaluation_metrics'], 'loops': ['applications_of_ai', 'ml_definitions_and_examples'], 'functions': [], 'classes': ['logical_agents', 'evaluation_metrics'], 'ml_definitions_and_examples': [], 'supervised_learning': ['unsupervised_learning'], 'unsupervised_learning': [], 'training_testing': ['rational_agents'], 'validation': [], 'evaluation_metrics': [], 'neural_networks_intro': [], 'perceptron': [], 'xor_problem': [], 'deep_learning': ['supervised_learning'], 'ml_project': [], 'ethical_ai': [], 'ai_potential': ['ml_definitions_and_examples'], 'llms_and_chatgpt': [], 'congrats': []}\n",
      "All Descendants: {'conditionals': [], 'classes': [], 'neural_networks_intro': [], 'unsupervised_learning': ['supervised_learning'], 'congrats': [], 'llms_and_chatgpt': [], 'loops': [], 'ml_definitions_and_examples': ['loops', 'ai_potential'], 'supervised_learning': ['deep_learning'], 'ml_project': [], 'collections': [], 'operators': [], 'functions': [], 'validation': [], 'ai_intro_and_definitions': [], 'training_testing': [], 'ethical_ai': [], 'applications_of_ai': ['loops'], 'evaluation_metrics': ['classes', 'collections'], 'search': [], 'deep_learning': [], 'history_of_ai': [], 'rational_agents': ['training_testing'], 'hello_world': [], 'ai_potential': [], 'perceptron': [], 'xor_problem': [], 'logical_agents': ['classes', 'collections']}\n",
      "Parents: {'conditionals': [], 'classes': [], 'neural_networks_intro': [], 'unsupervised_learning': ['supervised_learning'], 'congrats': [], 'llms_and_chatgpt': [], 'loops': [], 'ml_definitions_and_examples': ['loops', 'ai_potential'], 'supervised_learning': ['deep_learning'], 'ml_project': [], 'collections': [], 'operators': [], 'functions': [], 'validation': [], 'ai_intro_and_definitions': [], 'training_testing': [], 'ethical_ai': [], 'applications_of_ai': ['loops'], 'evaluation_metrics': ['classes', 'collections'], 'search': [], 'deep_learning': [], 'history_of_ai': [], 'rational_agents': ['training_testing'], 'hello_world': [], 'ai_potential': [], 'perceptron': [], 'xor_problem': [], 'logical_agents': ['classes', 'collections']}\n",
      "All Ancestors: {'conditionals': [], 'classes': [], 'neural_networks_intro': [], 'unsupervised_learning': ['supervised_learning', 'deep_learning'], 'congrats': [], 'llms_and_chatgpt': [], 'loops': [], 'ml_definitions_and_examples': ['loops', 'ai_potential'], 'supervised_learning': ['deep_learning'], 'ml_project': [], 'collections': [], 'operators': [], 'functions': [], 'validation': [], 'ai_intro_and_definitions': [], 'training_testing': [], 'ethical_ai': [], 'applications_of_ai': ['loops'], 'evaluation_metrics': ['classes', 'collections'], 'search': [], 'deep_learning': [], 'history_of_ai': [], 'rational_agents': ['training_testing'], 'hello_world': [], 'ai_potential': [], 'perceptron': [], 'xor_problem': [], 'logical_agents': ['classes', 'collections']}\n"
     ]
    }
   ],
   "source": [
    "progression_tree = progression_tree_build_2\n",
    "print(\"Children: \" + str(progression_tree.return_children()))\n",
    "print(\"All Descendants: \" + str(progression_tree.return_all_descendants()))\n",
    "print(\"Parents: \" + str(progression_tree.return_parents()))\n",
    "print(\"All Ancestors: \" + str(progression_tree.return_all_ancestors()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
